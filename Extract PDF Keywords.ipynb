{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7d76462",
   "metadata": {},
   "source": [
    "Import libraries  *DO NOT EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2ad82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2                    # open and pdf manipulation\n",
    "import os                        # change working directory\n",
    "import pandas as pd              # df manipulation\n",
    "from datetime import date        # extract date for csv title output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1742addc",
   "metadata": {},
   "source": [
    "Inputs (user specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ffde6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory locations of documents\n",
    "papers_dir = 'C:\\\\Users\\\\redinger\\\\Documents\\\\GLANSIS_folder\\\\Endnote_species\\\\Pistia stratiotes\\\\Pistia stratiotes PDFs'\n",
    "csv_dir = 'C:\\\\Users\\\\redinger\\\\Documents\\\\GLANSIS_folder\\\\Endnote_species\\\\Pistia stratiotes\\\\P.stratiotes_references_5.21.csv'\n",
    "export_dir = 'C:\\\\Users\\\\redinger\\\\Documents\\\\GLANSIS_folder\\\\Endnote_species\\\\Pistia stratiotes'\n",
    "\n",
    "# enter scientific and common names so they can be added to keywords -- keep names between quotation marks and be sure to use commas\n",
    "names = 'Pistia stratiotes, water lettuce' #used for keywords\n",
    "scientific_name = 'Pistia_stratiotes' #used only for naming documents\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39869945",
   "metadata": {},
   "source": [
    "Extract Keywords *DO NOT EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6334025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract keywords from metadata in text\n",
    "def extract_keywords_from_pdf(file_path):\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf = PyPDF2.PdfReader(file)\n",
    "        try:\n",
    "            pdf_keywords = pdf.metadata['/Keywords'].replace(';',',')\n",
    "        except KeyError:\n",
    "            pdf_keywords = ''\n",
    "    return pdf_keywords\n",
    "## Note to self - this does not capture everything. Need to come with better alternative to except KeyError:\n",
    "\n",
    "\n",
    "# Pull keywords from pdfs in folder file\n",
    "results = []\n",
    "for filename in os.listdir(papers_dir):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_path = os.path.join(papers_dir, filename)\n",
    "        pdf_keywords = extract_keywords_from_pdf(file_path)\n",
    "        results.append([filename, pdf_keywords])\n",
    "        \n",
    "\n",
    "# convert to data frame\n",
    "col_names = [\"file.name\", \"pdf_keywords\"]\n",
    "df = pd.DataFrame(results, columns = col_names)\n",
    "\n",
    "\n",
    "# combine keywords with common and scientific names\n",
    "df['keywords'] = names + ', ' + df['pdf_keywords'].astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0005ee07",
   "metadata": {},
   "source": [
    "Clean keywords - remove duplicates and extra characters from keywords *DO NOT EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03cbec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop original pdf_keywords\n",
    "df.drop('pdf_keywords', axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# function to remove duplicates from addition of common and scientific names\n",
    "def remove_duplicates(keywords_col):\n",
    "    words = keywords_col.split(',')\n",
    "    unique_words = list(set(words))\n",
    "    return ', '.join(unique_words)\n",
    "\n",
    "df['keywords'] = df['keywords'].apply(remove_duplicates)\n",
    "\n",
    "\n",
    "# function to remove anything before first keyword\n",
    "def remove_pre(keywords_col):\n",
    "    first_letter_index = next((index for index, char in enumerate(keywords_col) if char.isalpha()), -1)\n",
    "    if first_letter_index != -1:\n",
    "        return keywords_col[first_letter_index:]\n",
    "    return keywords_col\n",
    "\n",
    "df['keywords'] = df['keywords'].apply(remove_pre)\n",
    "\n",
    "\n",
    "# export output to csv file\n",
    "os.chdir(export_dir)\n",
    "df.to_csv('keywords' + '_' + scientific_name + '_' + str(date.today()) + '.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9eb3fc",
   "metadata": {},
   "source": [
    "Combine with csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a31dc6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload csv with clean references\n",
    "ref = pd.read_csv(csv_dir, encoding = 'cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31653af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on file names\n",
    "output = ref.merge(df, left_on = 'File Attachments', right_on = 'file.name', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ae472c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export new file\n",
    "output.to_csv(scientific_name + '_' + str(date.today()) + '.csv', index = False, encoding = 'cp1252')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "extract_keywords",
   "language": "python",
   "name": "extract_keywords"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
